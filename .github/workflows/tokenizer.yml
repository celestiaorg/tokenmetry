name: Token Telemetry

on:
  schedule:
    # Run daily at 6 AM UTC
    - cron: '0 6 * * *'
  workflow_dispatch: # Allow manual triggering
  push:
    branches: [ main ]
    paths:
      - 'tokenizer.py'
      - '.github/workflows/tokenizer.yml'
      - 'repos.txt'

permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  analyze-tokens:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
        
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true
        
    - name: Load cached venv
      id: cached-poetry-dependencies
      uses: actions/cache@v4
      with:
        path: .venv
        key: venv-${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-${{ hashFiles('**/poetry.lock') }}
        
    - name: Install dependencies
      if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
      run: poetry install --no-interaction --no-root
      
    - name: Run token analysis and prepare for deployment
      run: |
        # Create deployment directory
        mkdir -p _site
        
        # Run token analysis and output directly to deployment directory
        poetry run python tokenizer.py --celestia-repos --output _site/index.json
        
        # Add metadata for AI agents
        python3 << 'EOF'
        import json
        from datetime import datetime, timezone
        
        # Load existing results
        with open('_site/index.json', 'r') as f:
            data = json.load(f)
        
        # Add metadata for AI agents
        data['metadata'] = {
            'generated_at': datetime.now(timezone.utc).isoformat(),
            'generator': 'celestiaorg/tokenmetry',
            'version': '1.0.0',
            'format': 'celestia-token-telemetry-v1',
            'description': 'Token count analysis of CelestiaOrg repositories',
            'api_endpoint': 'https://celestiaorg.github.io/tokenmetry/index.json',
            'usage': 'This JSON file contains comprehensive token analysis of CelestiaOrg repositories for AI agent consumption'
        }
        
        # Save updated results
        with open('_site/index.json', 'w') as f:
            json.dump(data, f, indent=2)
        EOF
        
    - name: Setup Pages
      uses: actions/configure-pages@v4
      
    - name: Upload artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: './_site'
        
  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: analyze-tokens
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
